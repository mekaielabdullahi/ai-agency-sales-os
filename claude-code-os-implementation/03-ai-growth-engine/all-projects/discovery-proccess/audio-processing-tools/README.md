# Audio Processing Tools Library

A collection of reusable audio transcription and processing tools for client discovery calls and meetings.

## ğŸ¯ Purpose

These tools help automate the transcription and analysis of client discovery calls, enabling efficient extraction of insights for AI audits and project scoping.

## ğŸ“ Structure

```
audio-processing-tools/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ whisper-local/               # Local Whisper processing (no API)
â”‚   â”œâ”€â”€ install-whisper.sh      # Setup script
â”‚   â”œâ”€â”€ process-audio.py        # Python processor
â”‚   â””â”€â”€ batch-processor.sh      # Batch processing script
â”œâ”€â”€ whisper-api/                 # OpenAI Whisper API
â”‚   â”œâ”€â”€ api-processor.py        # API-based processing
â”‚   â””â”€â”€ compress-for-api.sh     # File compression utility
â”œâ”€â”€ transcription-utils/         # Utility scripts
â”‚   â”œâ”€â”€ merge-transcripts.py    # Combine multiple transcripts
â”‚   â”œâ”€â”€ extract-insights.py     # Extract key points
â”‚   â””â”€â”€ format-transcript.py    # Format for readability
â””â”€â”€ templates/                   # Reusable templates
    â”œâ”€â”€ discovery-analysis.md    # Discovery call template
    â””â”€â”€ audit-insights.json      # Structured insights format
```

## ğŸš€ Quick Start

### Option 1: Local Whisper (Free, No API)
```bash
cd whisper-local
./install-whisper.sh
./batch-processor.sh /path/to/audio/files
```

### Option 2: OpenAI API (Fast, Requires Key)
```bash
export OPENAI_API_KEY='your-key'
cd whisper-api
python api-processor.py /path/to/audio/files
```

## ğŸ”§ Features

### Core Capabilities
- âœ… Process WAV, MP3, MP4, M4A audio files
- âœ… Support for multiple speakers
- âœ… Batch processing of multiple files
- âœ… Automatic transcript merging
- âœ… Key insight extraction
- âœ… Python 3.13 compatibility

### Processing Options
| Method | Speed | Cost | Accuracy | Best For |
|--------|-------|------|----------|----------|
| Local Tiny | Fast | Free | 70% | Quick drafts |
| Local Base | Medium | Free | 85% | Standard calls |
| Local Large | Slow | Free | 95% | Critical content |
| API Whisper | Fast | ~$0.006/min | 90% | Production |

## ğŸ“Š Typical Workflow

1. **Record Discovery Call** â†’ Multiple audio files
2. **Process with Whisper** â†’ Individual transcripts
3. **Merge Transcripts** â†’ Combined document
4. **Extract Insights** â†’ Pain points, budget, timeline
5. **Update Audit** â†’ Populate audit.json
6. **Generate Report** â†’ Client deliverables

## ğŸ™ï¸ Audio File Guidelines

### Optimal Settings
- **Format:** WAV or MP3
- **Sample Rate:** 16kHz-48kHz
- **Channels:** Mono preferred
- **Bitrate:** 64kbps+ for speech
- **File Size:** <25MB for API, unlimited for local

### Large File Handling
```bash
# Compress large WAV to MP3
ffmpeg -i input.wav -acodec mp3 -ab 64k output.mp3

# Split long recordings
ffmpeg -i input.wav -f segment -segment_time 1800 -c copy output%03d.wav
```

## ğŸ’¡ Best Practices

### Recording Tips
1. Use separate audio tracks per speaker when possible
2. Minimize background noise
3. Test audio levels before important calls
4. Keep files under 2 hours for faster processing

### Processing Tips
1. Start with 'base' model for balance
2. Use 'tiny' for quick tests
3. Reserve 'large' for final versions
4. Process overnight for multiple files

### Organization Tips
1. Name files with speaker and timestamp
2. Keep originals separate from processed
3. Archive transcripts with project
4. Version control transcript edits

## ğŸ” Common Issues & Solutions

### Issue: Python version incompatibility
**Solution:** Use Python 3.13 virtual environment
```bash
python3.13 -m venv whisper-env
source whisper-env/bin/activate
```

### Issue: Files too large for API
**Solution:** Compress first
```bash
ffmpeg -i large.wav -acodec mp3 -ab 64k small.mp3
```

### Issue: Poor transcription quality
**Solution:** Try larger model or clean audio
```bash
whisper audio.wav --model large --language en
```

### Issue: Out of memory
**Solution:** Use smaller model or process in chunks
```bash
whisper audio.wav --model tiny --fp16 False
```

## ğŸ“ˆ Performance Benchmarks

| File Size | Model | Processing Time | Accuracy |
|-----------|-------|----------------|----------|
| 100MB WAV | tiny | 10 min | 70% |
| 100MB WAV | base | 20 min | 85% |
| 100MB WAV | large | 60 min | 95% |
| 10MB MP3 | API | 30 sec | 90% |

## ğŸ”— Integration Examples

### With AI Audit System
```python
from audio_tools import process_discovery_call
from audit_tools import update_audit_json

# Process audio
transcripts = process_discovery_call("client_audio/")

# Extract insights
insights = extract_pain_points(transcripts)

# Update audit
update_audit_json("audit.json", insights)
```

### With Project Management
```bash
# Process client call
./process-client-call.sh "Plotter Mechanix" /path/to/audio

# Output goes to project folder
ls active-projects/plotter-mechanix/transcripts/
```

## ğŸš¦ Tool Status

| Tool | Status | Version | Last Updated |
|------|--------|---------|--------------|
| Local Whisper | âœ… Active | 1.0 | 2025-12-08 |
| API Processor | âœ… Active | 1.0 | 2025-12-08 |
| Batch Processor | âœ… Active | 1.0 | 2025-12-08 |
| Insight Extractor | ğŸ”„ In Dev | 0.5 | 2025-12-08 |

## ğŸ“ License & Credits

- OpenAI Whisper: MIT License
- Scripts: Internal use
- Maintained by: AI Agency Development OS Team

---

**Need help?** Check individual tool READMEs or run with `--help` flag.